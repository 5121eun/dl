{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b97860c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import torch\n",
    "from torch import nn, Tensor\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from dataset import sequence\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from models.transformer import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "69d3b67c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model: nn.Module, optim: torch.optim, x: Tensor, t:Tensor, batch_size: int, max_epoch: int) -> list:\n",
    "    loss_list = []\n",
    "    \n",
    "    model.train()\n",
    "    for epoch in range(max_epoch):\n",
    "        idx = np.random.permutation(np.arange(data_size))\n",
    "        x = x[idx]\n",
    "        t = t[idx]\n",
    "\n",
    "        for iters in range(len(x) // batch_size):\n",
    "            batch_x = x[(iters * batch_size) : (iters + 1) * batch_size]\n",
    "            batch_t = t[(iters * batch_size) : (iters + 1) * batch_size]\n",
    "\n",
    "            batch_x = torch.Tensor(batch_x).type(torch.long)\n",
    "            batch_t = torch.Tensor(batch_t).type(torch.long)\n",
    "\n",
    "            target = batch_t[:, 1:]\n",
    "            batch_t = batch_t[:, :-1]\n",
    "\n",
    "            mask = model.get_seq_mask(batch_t.shape[1])\n",
    "\n",
    "            output = model.forward(batch_x, batch_t, mask)\n",
    "            loss = criterion(output.view(-1, ntokens), target.reshape(-1))\n",
    "\n",
    "            optim.zero_grad()\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "            \n",
    "            loss_list += [loss.item()]\n",
    "            \n",
    "            if iters % 20 == 0:\n",
    "                print(f'{epoch}({iters}): {loss.item()}')\n",
    "            \n",
    "    return loss_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d5b25e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model: nn.Module, optim: torch.optim, x: Tensor, t:Tensor, batch_size: int) -> list:\n",
    "    loss_list = []\n",
    "    \n",
    "    model.eval()\n",
    "    for iters in range(len(x) // batch_size):\n",
    "        batch_x = x[(iters * batch_size) : (iters + 1) * batch_size]\n",
    "        batch_t = t[(iters * batch_size) : (iters + 1) * batch_size]\n",
    "        \n",
    "        batch_x = torch.Tensor(batch_x).type(torch.long)\n",
    "        batch_t = torch.Tensor(batch_t).type(torch.long)\n",
    "        \n",
    "        target = batch_t[:, 1:]\n",
    "        batch_t = batch_t[:, :-1]\n",
    "        \n",
    "        mask = model.get_seq_mask(batch_t.shape[1])\n",
    "        \n",
    "        output = model.forward(batch_x, batch_t, mask)\n",
    "        loss = criterion(output.view(-1, ntokens), target.reshape(-1))\n",
    "        \n",
    "        loss_list += [loss.item()]\n",
    "        \n",
    "        if iters % 20 == 0:\n",
    "            print(f'{iters}: {loss.item()}')\n",
    "            \n",
    "    return loss_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bdbc3b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(model: nn.Module, x: Tensor, t:Tensor, token_id: int, seq_len: int):\n",
    "    b, n = x.shape\n",
    "    x = torch.Tensor(x).type(torch.long)\n",
    "    mask = model.get_seq_mask(seq_len)\n",
    "    pred = model.generate(x, torch.Tensor([token_id]).repeat(b).unsqueeze(-1).type(torch.long), seq_len, mask)\n",
    "    \n",
    "    \n",
    "    for b in range(b):\n",
    "        query = ''.join(id_to_char[x] for x in x[b].numpy())\n",
    "        target = ''.join(id_to_char[x] for x in t[b])\n",
    "        a = ''.join(id_to_char[x] for x in pred[b].numpy())\n",
    "\n",
    "        print(f'Q: {query}')\n",
    "        print(f'T: {target}')\n",
    "        print(f'{\"O\" if target == a else \"X\"}: {a}')\n",
    "        print('--')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3fdecf59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_graph(loss_list: list, label: str):\n",
    "    iters = np.arange(len(train_loss))\n",
    "    plt.plot(iters, train_loss, label='train')\n",
    "    plt.xlabel('iters')\n",
    "    plt.ylabel(label)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cb73e376",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, t_train), (x_test, t_test) = sequence.load_data('date.txt')\n",
    "char_to_id, id_to_char = sequence.get_vocab()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "91710d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ntokens = len(char_to_id)\n",
    "max_len = 100\n",
    "d_model = 128\n",
    "d_ff = d_model * 4\n",
    "nheads = 2\n",
    "nlayers = 2\n",
    "max_len = 100\n",
    "seq_len = t_train.shape[1] - 1\n",
    "learning_rate = 6e-4\n",
    "\n",
    "batch_size = 64\n",
    "max_epoch = 3\n",
    "data_size = len(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e008f808",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Transformer(max_len, ntokens, d_model, nheads, d_ff, nlayers)\n",
    "optim = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1afb660",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0(0): 61.17148971557617\n",
      "0(20): 3.2936928272247314\n",
      "0(40): 1.9102089405059814\n",
      "0(60): 1.7076330184936523\n",
      "0(80): 1.5900615453720093\n",
      "0(100): 1.5406310558319092\n",
      "0(120): 1.5421806573867798\n",
      "0(140): 1.540207862854004\n",
      "0(160): 1.48826265335083\n",
      "0(180): 1.5049744844436646\n",
      "0(200): 1.456982135772705\n",
      "0(220): 1.481579065322876\n",
      "0(240): 1.4611189365386963\n",
      "0(260): 1.504856824874878\n",
      "0(280): 1.4266360998153687\n",
      "0(300): 1.4146411418914795\n",
      "0(320): 1.3832087516784668\n",
      "0(340): 1.34346604347229\n",
      "0(360): 1.3736015558242798\n",
      "0(380): 1.323213815689087\n",
      "0(400): 1.3603177070617676\n",
      "0(420): 1.3559712171554565\n",
      "0(440): 1.2796876430511475\n",
      "0(460): 1.2747551202774048\n",
      "0(480): 1.1789920330047607\n",
      "0(500): 1.0766452550888062\n",
      "0(520): 1.0884976387023926\n",
      "0(540): 1.006840467453003\n",
      "0(560): 0.9062819480895996\n",
      "0(580): 0.9025230407714844\n",
      "0(600): 0.7783195972442627\n",
      "0(620): 0.6859427690505981\n",
      "0(640): 0.7368806600570679\n",
      "0(660): 0.6920230984687805\n",
      "0(680): 0.7519000172615051\n",
      "0(700): 0.6632137298583984\n",
      "1(0): 0.6843469738960266\n",
      "1(20): 0.6396132111549377\n",
      "1(40): 0.6237664222717285\n",
      "1(60): 0.6765044927597046\n",
      "1(80): 0.5880677103996277\n",
      "1(100): 0.5530234575271606\n",
      "1(120): 0.5867243409156799\n",
      "1(140): 0.5582839250564575\n",
      "1(160): 0.5465817451477051\n",
      "1(180): 0.4232092797756195\n",
      "1(200): 0.45574697852134705\n",
      "1(220): 0.47904324531555176\n",
      "1(240): 0.48286953568458557\n"
     ]
    }
   ],
   "source": [
    "train_loss = train(model, optim, x_train, t_train, batch_size, max_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a69a378f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss = evaluate(model, optim, x_train, t_train, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b84c2a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_graph(train_loss, 'train loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57fb4a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate(model, x_test[:10], t_test[:10, 1:], 14, 10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
